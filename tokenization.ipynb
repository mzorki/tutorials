{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tokenization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN1vc44+4hceUiQ8X7CQYgT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mzorki/tutorials/blob/main/tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfhBcaaddaqc"
      },
      "source": [
        "# Step 1. Import all the required libraries.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cbWOX4sdfRI"
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from pandas import json_normalize\n",
        "from tqdm.notebook import tqdm \n",
        "import re"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKKloeRehxie"
      },
      "source": [
        "# Step 2. Mount Google Drive\n",
        "For Colab to be able to work with Google Drive as a normal directory, we need to give it permissions to do so and tell it the place where this notebook is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ptoy-2APeBfk",
        "outputId": "a8127bbc-e9fc-457f-dbe2-e2fd5f895a53"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZE4Ut3BejKv"
      },
      "source": [
        "Input the path to the project. Generally starts with \"gdrive/My Drive/\" + path to the project folder. In my case, I have a folder \"Digital Orientalist\" in the Google Drive first level folder called \"My Drive\", hence the path."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SVQve9leLix",
        "outputId": "38d0cd6f-adb1-4b1e-c3fd-3efc63d86c2b"
      },
      "source": [
        "project_dir = \"/gdrive/My Drive/Digital Orientalist/\" \n",
        "#move to the working directory \n",
        "%cd {project_dir} "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/Digital Orientalist\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48lDwy0UhbC6"
      },
      "source": [
        "# Step 2. Save the path to the dictionary.\n",
        "\n",
        "CDICT (Stardict) dictionary is used in this notebook.\n",
        "To use a custom dictionary:\n",
        "- create a .txt file with one word per line\n",
        "- upload the dictionary to the project folder\n",
        "- change the file name below "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYTm39aEi7XG"
      },
      "source": [
        "dictionary_path = 'CDICT(Stardict)_wordlist.txt'"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uk5LWUand0H3"
      },
      "source": [
        "# Step 2. Load the text that we need to tokenize.\n",
        "For that we need to tell this notebook to use google drive as a directory of folders and give permissions to read files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymumL1HnfmHo"
      },
      "source": [
        "# Jieba"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVFLC0yBeVXg"
      },
      "source": [
        "import jieba"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibW9LxbOf3O6"
      },
      "source": [
        "text = \"你好！我是一個學生。\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqGUWS-XgBcF",
        "outputId": "2db70016-466e-4b66-9657-7b06c88e54f4"
      },
      "source": [
        "seg_list = jieba.cut(text, cut_all=True)\n",
        "print(\"Full Mode: \" + \" \".join(seg_list))  # 全模式"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.984 seconds.\n",
            "Prefix dict has been built successfully.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Full Mode: 你好 ！ 我 是 一 個 學 生 。\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTXykS-tg2xG"
      },
      "source": [
        "Load the dictionary file. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSvedrlPgEOm"
      },
      "source": [
        "jieba.load_userdict(dictionary_path)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmXYL_YljdsG"
      },
      "source": [
        "# HanLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8unJnor7gXlE",
        "outputId": "84082f8c-8d0e-40b2-e9f2-9ddce2c2eb78"
      },
      "source": [
        "!pip install pyhanlp"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyhanlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/99/13078d71bc9f77705a29f932359046abac3001335ea1d21e91120b200b21/pyhanlp-0.1.66.tar.gz (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 5.4MB/s \n",
            "\u001b[?25hCollecting jpype1==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/09/e19ce27d41d4f66d73ac5b6c6a188c51b506f56c7bfbe6c1491db2d15995/JPype1-0.7.0-cp36-cp36m-manylinux2010_x86_64.whl (2.7MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 13.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyhanlp\n",
            "  Building wheel for pyhanlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyhanlp: filename=pyhanlp-0.1.66-py2.py3-none-any.whl size=29371 sha256=866ffd295202b4300d56170cb8fdb42b84e020745614d63cc7e447f5f42480cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/8d/5d/6b642484b1abd87474914e6cf0d3f3a15d8f2653e15ff60f9e\n",
            "Successfully built pyhanlp\n",
            "Installing collected packages: jpype1, pyhanlp\n",
            "Successfully installed jpype1-0.7.0 pyhanlp-0.1.66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rjli2FvjCkw",
        "outputId": "d683dde0-8978-4d3c-cd47-d9c1973f8759"
      },
      "source": [
        "import pyhanlp"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "下载 https://file.hankcs.com/hanlp/hanlp-1.7.8-release.zip 到 /usr/local/lib/python3.6/dist-packages/pyhanlp/static/hanlp-1.7.8-release.zip\n",
            "100.00%, 1 MB, 688 KB/s, 还有 0 分  0 秒   \n",
            "下载 https://file.hankcs.com/hanlp/data-for-1.7.5.zip 到 /usr/local/lib/python3.6/dist-packages/pyhanlp/static/data-for-1.7.8.zip\n",
            "91.51%, 583 MB, 7839 KB/s, 还有 0 分  7 秒   "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgjtGzoVjbx7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}