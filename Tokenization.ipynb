{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tokenization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOVDuYa6GBVDezHRy6cbGxH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mzorki/tutorials/blob/main/Tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPKpAUq9BDOn"
      },
      "source": [
        "# This tutorial\n",
        "\n",
        "Below is Python3 code for working with different types of tokenizers of Chinese language. The corresponding git repository and README file are here: https://github.com/mzorki/tutorials \n",
        "<br><br>\n",
        "This file can be also used by those who do not know how to code. Just follow the insctuctions and run the code in cells by pressing the \"play\" button in upper left corner. \n",
        "<br><br>\n",
        "For more information on tokenization, read this article in Digital Orientalist\n",
        "TODO insert.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfhBcaaddaqc"
      },
      "source": [
        "# Step 1. Import all the required libraries.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cbWOX4sdfRI"
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from pandas import json_normalize\n",
        "from tqdm.notebook import tqdm \n",
        "import re"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKKloeRehxie"
      },
      "source": [
        "# Step 2. Mount Google Drive\n",
        "For Colab to be able to work with Google Drive as a normal directory, we need to give it permissions to do so and tell it the place where this notebook is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ptoy-2APeBfk",
        "outputId": "b241f755-9ea0-4775-b3fe-47d76e881b44"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZE4Ut3BejKv"
      },
      "source": [
        "Input the path to the project. Generally starts with \"gdrive/My Drive/\" + path to the project folder. In my case, I have a folder \"Digital Orientalist\" in the Google Drive first level folder called \"My Drive\", hence the path."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SVQve9leLix",
        "outputId": "a7e6ab1e-bae9-4543-e901-3e889ba7984d"
      },
      "source": [
        "project_dir = \"/gdrive/My Drive/Digital Orientalist/\" \n",
        "#move to the working directory \n",
        "%cd {project_dir} "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/Digital Orientalist\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48lDwy0UhbC6"
      },
      "source": [
        "# Step 2. Save the paths to the dictionary and the text to tokenize.\n",
        "\n",
        "CDICT (Stardict) dictionary is used in this notebook.\n",
        "To use a custom dictionary:\n",
        "- create a .txt file with one word per line\n",
        "- upload the dictionary to the project folder\n",
        "- change the file name below \n",
        "\n",
        "To tokenize a text:\n",
        "- create a .txt file with the text to tokenize.\n",
        "- no special formatting is required for the text. On the other hand, if there was any, it might be lost after tokenization. \n",
        "- change the file name below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYTm39aEi7XG"
      },
      "source": [
        "dictionary_path = 'CDICT(Stardict)_wordlist.txt'\n",
        "text_path = 'test_text.txt'\n",
        "tok_text = open(text_path).read()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uk5LWUand0H3"
      },
      "source": [
        "# Step 2. Load the text that we need to tokenize.\n",
        "For that we need to tell this notebook to use google drive as a directory of folders and give permissions to read files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymumL1HnfmHo"
      },
      "source": [
        "# Jieba"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVFLC0yBeVXg"
      },
      "source": [
        "import jieba"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibW9LxbOf3O6"
      },
      "source": [
        "text = \"你好！我是一個學生。\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqGUWS-XgBcF",
        "outputId": "2db70016-466e-4b66-9657-7b06c88e54f4"
      },
      "source": [
        "seg_list = jieba.cut(text, cut_all=True)\n",
        "print(\"Full Mode: \" + \" \".join(seg_list))  # 全模式"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.984 seconds.\n",
            "Prefix dict has been built successfully.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Full Mode: 你好 ！ 我 是 一 個 學 生 。\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTXykS-tg2xG"
      },
      "source": [
        "Load the dictionary file. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSvedrlPgEOm"
      },
      "source": [
        "jieba.load_userdict(dictionary_path)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmXYL_YljdsG"
      },
      "source": [
        "# HanLP\n",
        "HanLP is a ... <br>\n",
        "It is not pre-installed by Google Colab, so we need to first install it and download all the necessary files for it to work. <br><br>\n",
        "**Important!**\n",
        "- keep an eye on data usage\n",
        "- after this file is closed, all the downloaded data will be deleted. So one needs to reinstall everything each time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8unJnor7gXlE",
        "outputId": "19891e05-1300-4635-93f4-692b48b917f5"
      },
      "source": [
        "!pip install pyhanlp\n",
        "import pyhanlp"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyhanlp in /usr/local/lib/python3.6/dist-packages (0.1.66)\n",
            "Requirement already satisfied: jpype1==0.7.0 in /usr/local/lib/python3.6/dist-packages (from pyhanlp) (0.7.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgjtGzoVjbx7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0za6uHJl_qk"
      },
      "source": [
        "# Udkanbun\n",
        "\n",
        "Udkanbun is ... <br>\n",
        "Once again, it needs to be installed before we can use it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTQuLrfcmB2j",
        "outputId": "8594ee3f-cc33-4e55-fe2a-ec6ef17f674b"
      },
      "source": [
        "!pip install udkanbun\n",
        "import udkanbun"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting udkanbun\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/88/dec18d7ad738edeaacb050e3285c09a567f767e2c4c2d730e9bd5d61e1c3/udkanbun-2.7.2.tar.gz (13.9MB)\n",
            "\u001b[K     |████████████████████████████████| 13.9MB 7.2MB/s \n",
            "\u001b[?25hCollecting ufal.udpipe>=1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/72/2b8b9dc7c80017c790bb3308bbad34b57accfed2ac2f1f4ab252ff4e9cb2/ufal.udpipe-1.2.0.3.tar.gz (304kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 63.4MB/s \n",
            "\u001b[?25hCollecting mecab-python3>=0.996.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/f0/b57bfb29abd6b898d7137f4a276a338d2565f28a2098d60714388d119f3e/mecab_python3-1.0.3-cp36-cp36m-manylinux1_x86_64.whl (487kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 62.8MB/s \n",
            "\u001b[?25hCollecting deplacy>=1.8.9\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/85/707706dbc2e0626b5408c2469908810e5c4d5374995745bca04f450f41ec/deplacy-1.8.9-py3-none-any.whl\n",
            "Building wheels for collected packages: udkanbun, ufal.udpipe\n",
            "  Building wheel for udkanbun (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for udkanbun: filename=udkanbun-2.7.2-cp36-none-any.whl size=13895095 sha256=70cfcf16ef911d62ee9ea90f757d285881df38abafab57b0b67e9ecb739d877b\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/f9/df/2a5f53386ce1299babae799e6185e71b8e6028485faf47d7eb\n",
            "  Building wheel for ufal.udpipe (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ufal.udpipe: filename=ufal.udpipe-1.2.0.3-cp36-cp36m-linux_x86_64.whl size=5625253 sha256=7a529ad9ec46991a9083db458c0730f080aae78c33298130fdc2f940cb043113\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/9d/db/6d3404c33da5b7adb6c6972853efb6a27649d3ba15f7e9bebb\n",
            "Successfully built udkanbun ufal.udpipe\n",
            "Installing collected packages: ufal.udpipe, mecab-python3, deplacy, udkanbun\n",
            "Successfully installed deplacy-1.8.9 mecab-python3-1.0.3 udkanbun-2.7.2 ufal.udpipe-1.2.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zcR7f60mCPM"
      },
      "source": [
        "lzh=udkanbun.load()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QinjTPxPoHFm"
      },
      "source": [
        "## Working with one phrase. Full information and syntactic trees."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZ6vbsHpnJKU"
      },
      "source": [
        "text = \"翦暴興先廢，除凶存昔亡。圓蓋歸天壤，方輿入地荒。\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TZtyQQ3nLtv"
      },
      "source": [
        "segmented_phrase = lzh(text)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5K5QAXonOc-",
        "outputId": "5126e0e4-51bf-491e-e746-4e4e1d7bc119"
      },
      "source": [
        "print(segmented_phrase)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# text = 翦暴興先廢，除凶存昔亡。\n",
            "1\t翦\t翦\tVERB\tv,動詞,行為,動作\t_\t6\tacl\t_\tSpaceAfter=No\n",
            "2\t暴\t暴\tVERB\tv,動詞,描写,態度\tDegree=Pos\t1\tobj\t_\tGloss=expose|SpaceAfter=No\n",
            "3\t興\t興\tVERB\tv,動詞,行為,動作\t_\t1\tparataxis\t_\tGloss=rise|SpaceAfter=No|Translit=兴\n",
            "4\t先\t先\tNOUN\tn,名詞,固定物,関係\tCase=Loc\t3\tobj\t_\tGloss=before|SpaceAfter=No\n",
            "5\t廢\t廢\tVERB\tv,動詞,変化,制度\t_\t3\tparataxis\t_\tGloss=abolish|SpaceAfter=No|Translit=废\n",
            "6\t，\t，\tPUNCT\ts,記号,読点,*\t_\t7\tnsubj\t_\tSpaceAfter=No\n",
            "7\t除\t除\tVERB\tv,動詞,行為,動作\t_\t0\troot\t_\tGloss=eliminate|SpaceAfter=No\n",
            "8\t凶\t凶\tVERB\tv,動詞,描写,形質\tDegree=Pos\t9\tadvmod\t_\tGloss=ill-omened|SpaceAfter=No\n",
            "9\t存\t存\tVERB\tv,動詞,存在,存在\t_\t7\tccomp\t_\tGloss=exist|SpaceAfter=No\n",
            "10\t昔\t昔\tNOUN\tn,名詞,時,*\tCase=Tem\t11\tobl:tmod\t_\tGloss=formerly|SpaceAfter=No\n",
            "11\t亡\t亡\tVERB\tv,動詞,変化,生物\t_\t9\tparataxis\t_\tGloss=be-lost|SpaceAfter=No\n",
            "12\t。\t。\tPUNCT\ts,記号,句点,*\t_\t7\tpunct\t_\tSpaceAfter=No\n",
            "\n",
            "# text = 圓蓋歸天壤，方輿入地荒。\n",
            "1\t圓\t圓\tNOUN\tn,名詞,描写,形質\t_\t3\tnsubj\t_\tSpaceAfter=No|Translit=圆\n",
            "2\t蓋\t蓋\tPART\tp,助詞,句頭,*\t_\t3\tdiscourse\t_\tGloss=why-not|SpaceAfter=No|Translit=盖\n",
            "3\t歸\t歸\tVERB\tv,動詞,行為,移動\t_\t0\troot\t_\tGloss=return|SpaceAfter=No|Translit=归\n",
            "4\t天\t天\tNOUN\tn,名詞,制度,場\tCase=Loc\t5\tcompound\t_\tGloss=heaven|SpaceAfter=No\n",
            "5\t壤\t壤\tNOUN\tn,名詞,固定物,地形\tCase=Loc\t3\tobj\t_\tGloss=soil|SpaceAfter=No\n",
            "6\t，\t，\tPUNCT\ts,記号,読点,*\t_\t9\tadvmod\t_\tSpaceAfter=No\n",
            "7\t方\t方\tVERB\tv,動詞,行為,動作\t_\t8\tamod\t_\tGloss=pattern|SpaceAfter=No\n",
            "8\t輿\t輿\tNOUN\tn,名詞,可搬,乗り物\t_\t9\tnsubj\t_\tGloss=carriage|SpaceAfter=No|Translit=舆\n",
            "9\t入\t入\tVERB\tv,動詞,行為,移動\t_\t3\tconj\t_\tGloss=enter|SpaceAfter=No\n",
            "10\t地\t地\tNOUN\tn,名詞,固定物,地形\tCase=Loc\t9\tobj\t_\tGloss=earth|SpaceAfter=No\n",
            "11\t荒\t荒\tVERB\tv,動詞,描写,形質\tDegree=Pos\t9\tparataxis\t_\tGloss=wild|SpaceAfter=No\n",
            "12\t。\t。\tPUNCT\ts,記号,句点,*\t_\t3\tpunct\t_\tSpaceAfter=No\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cX81wqFVnPb0",
        "outputId": "89549eb7-04e2-4dd1-8f8b-fab5a1aec10a"
      },
      "source": [
        "print(segmented_phrase.to_tree())"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "翦 ═╗═══╗<╗     acl\n",
            "暴 <╝   ║ ║     obj\n",
            "興 ═╗═╗<╝ ║     parataxis\n",
            "先 <╝ ║   ║     obj\n",
            "廢 <══╝   ║     parataxis\n",
            "， ═══════╝<╗   nsubj\n",
            "除 ═════╗═══╝═╗ root\n",
            "凶 <╗   ║     ║ advmod\n",
            "存 ═╝═╗<╝     ║ ccomp\n",
            "昔 <╗ ║       ║ obl:tmod\n",
            "亡 ═╝<╝       ║ parataxis\n",
            "。 <══════════╝ punct\n",
            "圓 <════╗       nsubj\n",
            "蓋 <════║═╗     discourse\n",
            "歸 ═══╗═╝═╝═╗═╗ root\n",
            "天 <╗ ║     ║ ║ compound\n",
            "壤 ═╝<╝     ║ ║ obj\n",
            "， <════╗   ║ ║ advmod\n",
            "方 <╗   ║   ║ ║ amod\n",
            "輿 ═╝<╗ ║   ║ ║ nsubj\n",
            "入 ═╗═╝═╝═╗<╝ ║ conj\n",
            "地 <╝     ║   ║ obj\n",
            "荒 <══════╝   ║ parataxis\n",
            "。 <══════════╝ punct\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0j_1_oYoX-B"
      },
      "source": [
        "Only save the text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2iyUbn6n1iT",
        "outputId": "ebf432ab-08d6-4495-d092-d0c1839057d5"
      },
      "source": [
        "print(\" \".join([i.form for i in segmented_phrase[1:]]))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "翦 暴 興 先 廢 ， 除 凶 存 昔 亡 。 圓 蓋 歸 天 壤 ， 方 輿 入 地 荒 。\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s39NDy6uob2I"
      },
      "source": [
        "## Working with a bigger text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyZ12-3vrIg_"
      },
      "source": [
        "temp = [i for i in tok_text.split('\\n') if i!='']"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "Kyx7dsBHsJFq",
        "outputId": "99e66d6d-e530-4ff7-aff5-cd92e0e0b754"
      },
      "source": [
        "#with open('output_text.txt', 'w') as fh:\n",
        "fh = open('output_text.txt', 'w')\n",
        "\n",
        "for phrase in tqdm(temp):\n",
        "  seg = lzh(phrase)\n",
        "  fh.write(f'{\" \".join([i.form for i in seg[1:]])}\\n')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e07851366d28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output_text.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mphrase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mseg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlzh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{\" \".join([i.form for i in seg[1:]])}\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDFr3EZNqEUo",
        "outputId": "e2d0f0c5-e682-4d96-bf74-7dfca8a32d07"
      },
      "source": [
        "print(\" \".join([i.form for i in segmented_text[1:]]))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "學 而 子 曰 ： 「 學 而 時 習 之 ， 不 亦 說 乎 ？ 有 朋 自 遠 方 來 ， 不 亦 樂 乎 ？ 人 不 知 而 不 慍 ， 不 亦 君子 乎 ？ 」 有子 曰 ： 「 其 為 人 也 孝 弟 ， 而 好 犯 上 者 ， 鮮 矣 ； 不 好 犯 上 ， 而 好 作 亂 者 ， 未 之 有 也 。 君子 務 本 ， 本 立 而 道 生 。 孝 弟 也 者 ， 其 為 仁 之 本 與 ！ 」 子 曰 ： 「 巧 言 令 色 ， 鮮 矣 仁 ！ 」 曾子 曰 ： 「 吾 日 三 省 吾 身 ： 為 人 謀 而 不 忠 乎 ？ 與 朋 友 交 而 不 信 乎 ？ 傳 不 習 乎 ？ 」 子 曰 ： 「 道 千 乘 之 國 ： 敬 事 而 信 ， 節 用 而 愛 人 ， 使 民 以 時 。 」 子 曰 ： 「 弟子 入 則 孝 ， 出 則 弟 ， 謹 而 信 ， 汎 愛 眾 ， 而 親 仁 。 行 有 餘 力 ， 則 以 學 文 。 」 子夏 曰 ： 「 賢 賢 易 色 ， 事 父 母 能 竭 其 力 ， 事 君 能 致 其 身 ， 與 朋 友 交 言 而 有 信 。 雖 曰 未 學 ， 吾 必 謂 之 學 矣 。 」 子 曰 ： 「 君子 不 重 則 不 威 ， 學 則 不 固 。 主 忠 信 ， 無 友 不 如 己 者 ， 過 則 勿 憚 改 。 」 曾子 曰 ： 「 慎 終 追 遠 ， 民 德 歸 厚 矣 。 」 子禽 問 於 子貢 曰 ： 「 夫子 至 於 是 邦 也 ， 必 聞 其 政 ， 求 之 與 ？ 抑 與 之 與 ？ 」 子貢 曰 ： 「 夫子 溫 、 良 、 恭 、 儉 、 讓 以 得 之 。 夫子 之 求 之 也 ， 其 諸 異 乎 人 之 求 之 與 ？ 」 子 曰 ： 「 父 在 ， 觀 其 志 ； 父 沒 ， 觀 其 行 ； 三 年 無 改 於 父 之 道 ， 可 謂 孝 矣 。 」 有子 曰 ： 「 禮 之 用 ， 和 為 貴 。 先 王 之 道 斯 為 美 ， 小 大 由 之 。 有 所 不 行 ， 知 和 而 和 ， 不 以 禮 節 之 ， 亦 不 可 行 也 。 」 有子 曰 ： 「 信 近 於 義 ， 言 可 復 也 ； 恭 近 於 禮 ， 遠 恥 辱 也 ； 因 不 失 其 親 ， 亦 可 宗 也 。 」 子 曰 ： 「 君子 食 無 求 飽 ， 居 無 求 安 ， 敏 於 事 而 慎 於 言 ， 就 有 道 而 正 焉 ， 可 謂 好 學 也 已 。 」 子貢 曰 ： 「 貧 而 無 諂 ， 富 而 無 驕 ， 何 如 ？ 」 子 曰 ： 「 可 也 。 未 若 貧 而 樂 ， 富 而 好 禮 者 也 。 」 子貢 曰 ： 「 《 詩 》 云 ： 『 如 切 如 磋 ， 如 琢 如 磨 。 』 其 斯 之 謂 與 ？ 」 子 曰 ： 「 賜 也 ， 始 可 與 言 詩 已 矣 ！ 告 諸 往 而 知 來 者 。 」 子 曰 ： 「 不 患 人 之 不 己 知 ， 患 不 知 人 也 。 」\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMxutJ0EqHDP"
      },
      "source": [
        "output_text = \" \".join([i.form for i in segmented_phrase[1:]])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjINWQ2MqRO_"
      },
      "source": [
        "\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhv1pekvqlTC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}